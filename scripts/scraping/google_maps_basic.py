#!/usr/bin/env python3
"""
Template: Google Maps Scraper - Busca B√°sica
=============================================

Busca simples por termo + localiza√ß√£o.
Uso r√°pido para extrair empresas/lugares do Google Maps.

Uso:
    python3 scripts/scraping/google_maps_basic.py "restaurantes" "S√£o Paulo, Brasil"
    python3 scripts/scraping/google_maps_basic.py "hot√©is" "Lisboa, Portugal" --max 50
"""

import sys
import os
import argparse

# Adiciona o diret√≥rio raiz ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from tools.apify_google_maps import GoogleMapsScraper


def main():
    parser = argparse.ArgumentParser(
        description="Google Maps Scraper - Busca B√°sica",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:

  # Restaurantes em S√£o Paulo (20 resultados)
  python3 scripts/scraping/google_maps_basic.py "restaurantes" "S√£o Paulo, Brasil"

  # Hot√©is no Rio (50 resultados)
  python3 scripts/scraping/google_maps_basic.py "hot√©is" "Rio de Janeiro" --max 50

  # Cafeterias em Lisboa (export CSV)
  python3 scripts/scraping/google_maps_basic.py "cafeterias" "Lisboa, Portugal" --csv

  # Academias em BH com reviews
  python3 scripts/scraping/google_maps_basic.py "academias" "Belo Horizonte" --reviews
        """
    )

    parser.add_argument('search', type=str, help='Termo de busca (ex: "restaurantes")')
    parser.add_argument('location', type=str, help='Localiza√ß√£o (ex: "S√£o Paulo, Brasil")')
    parser.add_argument('--max', type=int, default=20, help='M√°ximo de resultados (padr√£o: 20)')
    parser.add_argument('--csv', action='store_true', help='Exportar em CSV (padr√£o: JSON)')
    parser.add_argument('--reviews', action='store_true', help='Incluir reviews (5 por lugar)')
    parser.add_argument('--output', type=str, help='Nome do arquivo de sa√≠da')

    args = parser.parse_args()

    print("=" * 80)
    print("üó∫Ô∏è  GOOGLE MAPS SCRAPER - BUSCA B√ÅSICA")
    print("=" * 80)

    # Inicializa scraper
    scraper = GoogleMapsScraper()

    # Executa scraping
    results = scraper.scrape_by_search(
        search_query=args.search,
        location=args.location,
        max_results=args.max,
        include_reviews=args.reviews,
        max_reviews=5 if args.reviews else 0
    )

    # Salva resultados
    if results["success"]:
        output_format = "csv" if args.csv else "json"
        scraper.save_results(results, format=output_format, filename=args.output)
        print("=" * 80)
        print("‚úÖ Scraping conclu√≠do!")
        print("=" * 80)
    else:
        print(f"‚ùå Erro: {results['error']}")
        sys.exit(1)


if __name__ == "__main__":
    main()
