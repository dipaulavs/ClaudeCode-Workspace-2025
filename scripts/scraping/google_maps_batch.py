#!/usr/bin/env python3
"""
Template: Google Maps Scraper - Busca em Lote (Batch)
======================================================

Executa m√∫ltiplas buscas em paralelo e combina os resultados.
√ötil para extrair dados de v√°rias localiza√ß√µes ou termos de busca simultaneamente.

Uso:
    python3 scripts/scraping/google_maps_batch.py --searches "restaurantes,hot√©is,cafeterias" --location "S√£o Paulo"
    python3 scripts/scraping/google_maps_batch.py --search "academias" --locations "S√£o Paulo,Rio de Janeiro,Belo Horizonte"
"""

import sys
import os
import argparse
import json
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# Adiciona o diret√≥rio raiz ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from tools.apify_google_maps import GoogleMapsScraper
from config.apify_config import EXPORT_DIR


def scrape_single(scraper, search_query, location, max_results, include_reviews, max_reviews):
    """Executa um √∫nico scraping"""
    try:
        print(f"  üîÑ Iniciando: {search_query} em {location}")
        result = scraper.scrape_by_search(
            search_query=search_query,
            location=location,
            max_results=max_results,
            include_reviews=include_reviews,
            max_reviews=max_reviews
        )
        if result["success"]:
            print(f"  ‚úÖ Conclu√≠do: {search_query} em {location} ({result['num_places']} lugares)")
        else:
            print(f"  ‚ùå Erro: {search_query} em {location} - {result.get('error', 'Erro desconhecido')}")
        return result
    except Exception as e:
        print(f"  ‚ùå Exce√ß√£o: {search_query} em {location} - {str(e)}")
        return {"success": False, "error": str(e), "places": []}


def main():
    parser = argparse.ArgumentParser(
        description="Google Maps Scraper - Busca em Lote (Batch)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:

  # M√∫ltiplas buscas na mesma localiza√ß√£o
  python3 scripts/scraping/google_maps_batch.py \\
    --searches "restaurantes,hot√©is,cafeterias,academias" \\
    --location "S√£o Paulo, Brasil"

  # Mesma busca em m√∫ltiplas localiza√ß√µes
  python3 scripts/scraping/google_maps_batch.py \\
    --search "academias" \\
    --locations "S√£o Paulo,Rio de Janeiro,Belo Horizonte,Curitiba"

  # Combina√ß√£o de buscas e localiza√ß√µes (produto cartesiano)
  python3 scripts/scraping/google_maps_batch.py \\
    --searches "restaurantes,cafeterias" \\
    --locations "S√£o Paulo,Rio de Janeiro" \\
    --max 30

  # Com reviews e export CSV
  python3 scripts/scraping/google_maps_batch.py \\
    --search "hot√©is" \\
    --locations "Lisboa,Porto,Faro" \\
    --reviews --csv
        """
    )

    # Argumentos de busca
    parser.add_argument('--search', type=str, help='Termo de busca √∫nico')
    parser.add_argument('--searches', type=str, help='M√∫ltiplos termos de busca (separados por v√≠rgula)')
    parser.add_argument('--location', type=str, help='Localiza√ß√£o √∫nica')
    parser.add_argument('--locations', type=str, help='M√∫ltiplas localiza√ß√µes (separadas por v√≠rgula)')

    # Configura√ß√µes
    parser.add_argument('--max', type=int, default=20, help='M√°ximo de resultados por busca (padr√£o: 20)')
    parser.add_argument('--reviews', action='store_true', help='Incluir reviews')
    parser.add_argument('--max-reviews', type=int, default=5, help='M√°ximo de reviews por lugar (padr√£o: 5)')
    parser.add_argument('--workers', type=int, default=3, help='N√∫mero de buscas paralelas (padr√£o: 3)')

    # Export
    parser.add_argument('--csv', action='store_true', help='Exportar em CSV (padr√£o: JSON)')
    parser.add_argument('--output', type=str, help='Nome do arquivo de sa√≠da')
    parser.add_argument('--separate', action='store_true', help='Salvar cada busca em arquivo separado')

    args = parser.parse_args()

    # Valida argumentos
    if not (args.search or args.searches):
        print("‚ùå Erro: --search ou --searches √© obrigat√≥rio")
        sys.exit(1)

    if not (args.location or args.locations):
        print("‚ùå Erro: --location ou --locations √© obrigat√≥rio")
        sys.exit(1)

    # Processa listas
    search_queries = []
    if args.searches:
        search_queries = [s.strip() for s in args.searches.split(',')]
    elif args.search:
        search_queries = [args.search.strip()]

    locations = []
    if args.locations:
        locations = [l.strip() for l in args.locations.split(',')]
    elif args.location:
        locations = [args.location.strip()]

    # Cria lista de tarefas (produto cartesiano)
    tasks = []
    for search in search_queries:
        for location in locations:
            tasks.append((search, location))

    print("=" * 80)
    print("üó∫Ô∏è  GOOGLE MAPS SCRAPER - BUSCA EM LOTE")
    print("=" * 80)
    print(f"\nüìä Total de buscas: {len(tasks)}")
    print(f"üë∑ Workers paralelos: {args.workers}")
    print(f"üìç Localiza√ß√µes: {', '.join(locations)}")
    print(f"üîç Buscas: {', '.join(search_queries)}")
    print()

    # Inicializa scraper
    scraper = GoogleMapsScraper()

    # Executa buscas em paralelo
    all_results = []
    with ThreadPoolExecutor(max_workers=args.workers) as executor:
        futures = {}
        for search, location in tasks:
            future = executor.submit(
                scrape_single,
                scraper,
                search,
                location,
                args.max,
                args.reviews,
                args.max_reviews
            )
            futures[future] = (search, location)

        # Aguarda conclus√£o
        for future in as_completed(futures):
            search, location = futures[future]
            result = future.result()
            all_results.append({
                "search": search,
                "location": location,
                "result": result
            })

    # Processa resultados
    successful = [r for r in all_results if r["result"]["success"]]
    failed = [r for r in all_results if not r["result"]["success"]]

    print("\n" + "=" * 80)
    print(f"üìä RESUMO")
    print("=" * 80)
    print(f"‚úÖ Buscas bem-sucedidas: {len(successful)}")
    print(f"‚ùå Buscas com erro: {len(failed)}")

    if failed:
        print("\n‚ö†Ô∏è  Buscas que falharam:")
        for item in failed:
            print(f"  - {item['search']} em {item['location']}: {item['result'].get('error', 'Erro desconhecido')}")

    # Salva resultados
    if successful:
        output_format = "csv" if args.csv else "json"

        if args.separate:
            # Salva cada busca em arquivo separado
            print(f"\nüíæ Salvando resultados separados...")
            for item in successful:
                search = item["search"]
                location = item["location"]
                result = item["result"]

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"gmaps_{search.replace(' ', '_')}_{location.replace(' ', '_').replace(',', '')}_{timestamp}"

                scraper.save_results(result, format=output_format, filename=filename)

        else:
            # Combina todos os resultados em um √∫nico arquivo
            print(f"\nüíæ Salvando resultados combinados...")

            all_places = []
            for item in successful:
                places = item["result"]["places"]
                # Adiciona metadados de busca a cada lugar
                for place in places:
                    place["_search_query"] = item["search"]
                    place["_search_location"] = item["location"]
                all_places.extend(places)

            # Cria resultado combinado
            combined_result = {
                "success": True,
                "num_places": len(all_places),
                "places": all_places
            }

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = args.output or f"gmaps_batch_{timestamp}"

            scraper.save_results(combined_result, format=output_format, filename=filename)

    print("\n" + "=" * 80)
    print("‚úÖ Batch scraping conclu√≠do!")
    print("=" * 80)


if __name__ == "__main__":
    main()
