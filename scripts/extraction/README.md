# ğŸ” Templates de ExtraÃ§Ã£o de ConteÃºdo

Scripts prontos para extraÃ§Ã£o, transcriÃ§Ã£o e scraping de conteÃºdo de mÃºltiplas plataformas.

---

## ğŸ“‹ Templates DisponÃ­veis

| Template | FunÃ§Ã£o | Plataformas |
|----------|--------|-------------|
| **transcribe_video.py** | Transcreve vÃ­deos | YouTube, TikTok, Instagram, LinkedIn, X/Twitter, Vimeo |
| **extract_instagram.py** | Extrai posts IG | Instagram (posts, carrossÃ©is, perfis) |
| **scrape_website.py** | Scraping de sites | Qualquer site (conversÃ£o para Markdown) |
| **scrape_batch.py** | Scraping em batch | MÃºltiplos sites em sequÃªncia |

---

## ğŸ¬ TranscriÃ§Ã£o de VÃ­deos

### transcribe_video.py

Transcreve vÃ­deos de mÃºltiplas plataformas usando RapidAPI.

#### Uso BÃ¡sico

```bash
# YouTube em portuguÃªs
python3 scripts/extraction/transcribe_video.py "https://youtu.be/VIDEO_ID" --lang pt

# TikTok em inglÃªs (padrÃ£o)
python3 scripts/extraction/transcribe_video.py "https://tiktok.com/@user/video/123"

# Instagram Reel em espanhol
python3 scripts/extraction/transcribe_video.py "https://instagram.com/reel/ABC/" --lang es

# Traduzir para inglÃªs
python3 scripts/extraction/transcribe_video.py "URL" --task translate
```

#### Plataformas Suportadas

- âœ… YouTube (youtube.com, youtu.be)
- âœ… TikTok (tiktok.com)
- âœ… Instagram (instagram.com/reel, instagram.com/p)
- âœ… LinkedIn (linkedin.com)
- âœ… X/Twitter (x.com, twitter.com)
- âœ… Vimeo (vimeo.com)

#### Idiomas Suportados

| CÃ³digo | Idioma | CÃ³digo | Idioma |
|--------|--------|--------|--------|
| `pt` | PortuguÃªs | `en` | InglÃªs |
| `es` | Espanhol | `fr` | FrancÃªs |
| `de` | AlemÃ£o | `it` | Italiano |
| `ja` | JaponÃªs | `ko` | Coreano |
| `zh` | ChinÃªs | `ru` | Russo |

#### SaÃ­da

Arquivos salvos em: `~/Downloads/transcription_PLATFORM_TIMESTAMP/`

- `transcription.txt` - TranscriÃ§Ã£o formatada
- `transcription_full.json` - Dados completos da API

---

## ğŸ“¸ ExtraÃ§Ã£o de Posts do Instagram

### extract_instagram.py

Extrai imagens, vÃ­deos e legendas de posts do Instagram via Apify.

#### Uso BÃ¡sico

```bash
# Extrair um post especÃ­fico
python3 scripts/extraction/extract_instagram.py "https://www.instagram.com/p/ABC123/"

# Extrair posts de um perfil (Ãºltimos 30)
python3 scripts/extraction/extract_instagram.py "natgeo"

# Limitar quantidade de posts
python3 scripts/extraction/extract_instagram.py "natgeo" --limit 10

# Extrair carrossel completo
python3 scripts/extraction/extract_instagram.py "https://www.instagram.com/p/XYZ789/"
```

#### Recursos

- âœ… Extrai imagens em alta qualidade
- âœ… Baixa TODAS as imagens de carrossÃ©is
- âœ… Salva legendas completas
- âœ… Inclui metadados (likes, comentÃ¡rios, autor)
- âœ… Suporta posts individuais e perfis
- âœ… Suporta vÃ­deos (URLs extraÃ­das)

#### SaÃ­da

Arquivos salvos em: `~/Downloads/instagram_extract_TIMESTAMP/`

**Por post:**
- `post_01_img_01.jpg` - Primeira imagem
- `post_01_img_02.jpg` - Segunda imagem (se carrossel)
- `post_01_caption.txt` - Legenda e metadados
- `post_01_data.json` - Dados completos

---

## ğŸŒ Web Scraping de Sites

### scrape_website.py

Extrai conteÃºdo completo de sites e converte para Markdown via Apify.

#### Uso BÃ¡sico

```bash
# Scraping bÃ¡sico (ilimitado)
python3 scripts/extraction/scrape_website.py "https://docs.example.com"

# Limitar quantidade de pÃ¡ginas
python3 scripts/extraction/scrape_website.py "https://docs.site.com" --max-pages 50

# Controlar profundidade de crawling
python3 scripts/extraction/scrape_website.py "https://site.com" --max-depth 3

# Combinar limites
python3 scripts/extraction/scrape_website.py "https://site.com" --max-pages 100 --max-depth 5

# Pular preview e executar direto
python3 scripts/extraction/scrape_website.py "https://site.com" --no-preview
```

#### Recursos

- âœ… Preview automÃ¡tico antes de executar
- âœ… Segue links internos automaticamente
- âœ… Converte HTML para Markdown
- âœ… Salva pÃ¡ginas individuais + conteÃºdo completo
- âœ… Inclui metadata (tÃ­tulos, URLs, timestamps)
- âœ… Ideal para documentaÃ§Ãµes tÃ©cnicas

#### SaÃ­da

Arquivos salvos em: `~/Downloads/apify_scrape_DOMAIN_TIMESTAMP/`

- `page_001.md`, `page_002.md`, etc - PÃ¡ginas individuais
- `full_content.md` - ConteÃºdo completo concatenado
- `metadata.json` - InformaÃ§Ãµes de todas as pÃ¡ginas

#### Casos de Uso

- ğŸ“š Extrair documentaÃ§Ãµes tÃ©cnicas completas
- ğŸ” Fazer backup de sites para anÃ¡lise offline
- ğŸ“– Converter sites para formato legÃ­vel (Markdown)
- ğŸ¤– Preparar dados para treinamento de LLMs

---

## ğŸ”„ Web Scraping em Batch

### scrape_batch.py

Extrai conteÃºdo de mÃºltiplos sites em sequÃªncia via Apify.

#### Uso BÃ¡sico

```bash
# Scraping de 2 sites
python3 scripts/extraction/scrape_batch.py 'https://docs.site1.com' 'https://docs.site2.com'

# Scraping de mÃºltiplas documentaÃ§Ãµes
python3 scripts/extraction/scrape_batch.py \
  'https://docs.react.dev' \
  'https://docs.python.org/3' \
  'https://nodejs.org/docs'

# MÃºltiplas pÃ¡ginas de produtos
python3 scripts/extraction/scrape_batch.py \
  'https://site.com/product1' \
  'https://site.com/product2' \
  'https://site.com/product3'
```

#### Recursos

- âœ… Processa cada URL em sequÃªncia
- âœ… Salva cada site em pasta separada
- âœ… Preview automÃ¡tico para cada site
- âœ… Resumo final com estatÃ­sticas
- âœ… Tratamento de erros individual
- âœ… Pode ser interrompido (Ctrl+C) sem perder progresso

#### SaÃ­da

Cada site Ã© salvo em sua prÃ³pria pasta:

```
~/Downloads/
â”œâ”€â”€ apify_scrape_react_20250102_120000/
â”‚   â”œâ”€â”€ page_001.md
â”‚   â”œâ”€â”€ full_content.md
â”‚   â””â”€â”€ metadata.json
â”œâ”€â”€ apify_scrape_python_20250102_120530/
â”‚   â”œâ”€â”€ page_001.md
â”‚   â”œâ”€â”€ full_content.md
â”‚   â””â”€â”€ metadata.json
â””â”€â”€ apify_scrape_nodejs_20250102_121045/
    â”œâ”€â”€ page_001.md
    â”œâ”€â”€ full_content.md
    â””â”€â”€ metadata.json
```

#### Resumo Final

Ao concluir, o script exibe:

```
ğŸ“Š RESUMO FINAL
â±ï¸  Tempo total: 325.4 segundos
ğŸ“‹ URLs processadas: 3/3

âœ… Sucessos: 3
   â€¢ https://docs.react.dev (127 pÃ¡ginas)
     â””â”€ /Users/user/Downloads/apify_scrape_react_20250102_120000
   â€¢ https://docs.python.org/3 (243 pÃ¡ginas)
     â””â”€ /Users/user/Downloads/apify_scrape_python_20250102_120530
   â€¢ https://nodejs.org/docs (89 pÃ¡ginas)
     â””â”€ /Users/user/Downloads/apify_scrape_nodejs_20250102_121045
```

---

## âš™ï¸ ConfiguraÃ§Ã£o NecessÃ¡ria

### APIs Requeridas

| Template | API NecessÃ¡ria | Config |
|----------|----------------|--------|
| transcribe_video.py | RapidAPI (Speech-to-Text AI) | Hardcoded em `tools/transcribe_universal.py` |
| extract_instagram.py | Apify | Hardcoded em `tools/extract_instagram.py` |
| scrape_website.py | Apify | `config/apify_config.py` |
| scrape_batch.py | Apify | `config/apify_config.py` |

### Verificar ConfiguraÃ§Ãµes

```bash
# Verificar config Apify
cat config/apify_config.py

# Verificar API RapidAPI
grep "RAPIDAPI_KEY" tools/transcribe_universal.py
```

---

## ğŸ“Š Performance e Custos

| Template | Tempo MÃ©dio | Custo Estimado | Notas |
|----------|-------------|----------------|-------|
| **transcribe_video.py** | 1-5 min | ~$0.02/vÃ­deo | Depende da duraÃ§Ã£o do vÃ­deo |
| **extract_instagram.py** | 30-60s | ~$0.05/30 posts | Tempo de Apify |
| **scrape_website.py** | 1-10 min | ~$0.10-0.50/site | Depende do tamanho |
| **scrape_batch.py** | 5-30 min | ~$0.50-2.00/batch | MÃºltiplos sites |

**Nota:** Custos sÃ£o estimativas baseadas em uso mÃ©dio das APIs.

---

## ğŸš¨ Troubleshooting

### Erro: "NÃ£o foi possÃ­vel importar X"

```bash
# Verificar se arquivo existe
ls -la tools/transcribe_universal.py
ls -la tools/extract_instagram.py
ls -la tools/apify_scraper.py

# Verificar dependÃªncias
pip3 install --user requests apify-client
```

### Erro 401 - API Key InvÃ¡lida

```bash
# Apify
vim config/apify_config.py

# RapidAPI
vim tools/transcribe_universal.py
# Procurar por RAPIDAPI_KEY e atualizar
```

### Timeout em TranscriÃ§Ã£o

VÃ­deos muito longos podem dar timeout. SoluÃ§Ãµes:

1. Usar vÃ­deos menores (< 10 min)
2. Baixar o vÃ­deo e enviar direto (nÃ£o implementado ainda)

### Instagram nÃ£o retorna posts

1. Verificar se URL estÃ¡ correta
2. Verificar se perfil Ã© pÃºblico
3. Aumentar timeout em `tools/extract_instagram.py`

### Scraping retorna poucas pÃ¡ginas

1. Aumentar `--max-pages` e `--max-depth`
2. Site pode ter bloqueio anti-bot
3. Verificar se links internos estÃ£o corretos

---

## ğŸ’¡ Casos de Uso Reais

### 1. AnÃ¡lise de Concorrentes (Instagram)

```bash
# Extrair Ãºltimos 50 posts de 3 concorrentes
python3 scripts/extraction/extract_instagram.py "concorrente1" --limit 50
python3 scripts/extraction/extract_instagram.py "concorrente2" --limit 50
python3 scripts/extraction/extract_instagram.py "concorrente3" --limit 50

# Analisar padrÃµes de conteÃºdo, hashtags, engajamento
```

### 2. Transcrever Webinars para Blog

```bash
# Transcrever webinar do YouTube
python3 scripts/extraction/transcribe_video.py "https://youtu.be/WEBINAR_ID" --lang pt

# Usar transcriÃ§Ã£o como base para artigo de blog
```

### 3. Backup de DocumentaÃ§Ã£o

```bash
# Fazer backup de mÃºltiplas docs tÃ©cnicas
python3 scripts/extraction/scrape_batch.py \
  'https://docs.nossa-api.com' \
  'https://docs.nossa-plataforma.com' \
  'https://wiki.interna.com'
```

### 4. AnÃ¡lise de TendÃªncias (TikTok)

```bash
# Transcrever vÃ­deos virais para anÃ¡lise
python3 scripts/extraction/transcribe_video.py "https://tiktok.com/@user/video/123" --lang pt
python3 scripts/extraction/transcribe_video.py "https://tiktok.com/@user/video/456" --lang pt

# Analisar padrÃµes de linguagem, hooks, CTAs
```

---

## ğŸ”— Recursos Relacionados

- **Ferramentas originais:** `tools/`
  - `transcribe_universal.py` (transcriÃ§Ã£o)
  - `extract_instagram.py` (Instagram)
  - `apify_scraper.py` (web scraping)
  - `apify_scraper_batch.py` (batch scraping)

- **DocumentaÃ§Ã£o:**
  - `docs/tools/transcribe_universal.md` (transcriÃ§Ã£o)
  - `docs/tools/extract_instagram.md` (Instagram - se existir)
  - `docs/tools/apify_scraper.md` (scraping - se existir)

- **ConfiguraÃ§Ãµes:**
  - `config/apify_config.py` (Apify API)

---

## ğŸ“ Suporte

**Problemas com templates?**
1. Verificar logs de erro
2. Confirmar API keys configuradas
3. Testar ferramenta original em `tools/`
4. Reportar issue com detalhes

---

**Ãšltima atualizaÃ§Ã£o:** 2025-11-02
**Total de templates:** 4 (todos testados e funcionais)
